---
title: "CFA Practice Trial"
author: "firdaus"
format: 
  html:
    theme: cosmo
    toc: true
    toc-location: left
    toc-depth: 6
    number-sections: true
    self-contained: true
editor: visual
---

# Preliminaries

## Load Library

```{r}
library(readxl) 
library(foreign) 
library(psych) 
library(lavaan)  # for CFA 
library(semTools)  # for additional functions in SEM
library(semPlot)  # for path diagram
```

## Load Data

```{r}
data1 = read_excel("CFA_Practice_trial.xlsx")
names(data1)
head(data1)
```

Coding the answers

```{r}
# Define mapping function
likert_map <- function(x) {
  recode <- c(
    "Tidak pernah" = 1,
    "Jarang"        = 2,
    "Kadang-kadang"         = 3,
    "Selalu"              = 4,
    "Sentiasa"       = 5
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

# Apply transformation from data1 -> data2
data2 <- data1

for (col in names(data2)) {
  data2[[col]] <- likert_map(data2[[col]])
}

# Convert all to numeric
data2 <- as.data.frame(lapply(data2, as.numeric))
```

From EFA, we include only good items across PA1 till PA4.

PA1 ( Teaching Practices ) : P1, P2, P3, P4, P5, P6, P7, P8, P9, P16, P17 (11 items)

PA2 ( Monitoring and Responses) : P10, P11, P12, P13, P14 (5 items)

PA3 ( Involvement ): P15, P18, P19, P20, P21, P22 (6 items)

```{r}
data.cfa = data2[c("P1", "P2","P3", "P4", "P5", "P6", "P7", "P8", "P9", "P10", "P11", "P12", "P13", "P14", "P15", "P16", "P17", "P18", "P19", "P20", "P21", "P22")]
```

```{r}
str(data.cfa)
```

```{r}
dim(data.cfa)
```

```{r}
names(data.cfa)
```

```{r}
head(data.cfa)
```

# Confirmatory factor analysis

## Preliminary steps

### **Descriptive statistics**

Check minimum/maximum values per item, and screen for any missing values,

```{r}
describe(data.cfa)
```

Note that all *n* = 204, no missing values. `min`–`max` cover the whole range of response options.

\% of response to options per item,

```{r}
response.frequencies(data.cfa)
```

### **Multivariate normality**

This is done to check the multivariate normality of the data. If the data are normally distributed, we may use maximum likelihood (ML) estimation method for the CFA.

```{r}
mardia(data.cfa)
```

the data are not multivariate normal (`kurtosis` \> 5, *P* \< 0.05). We will use **MLR** in our analysis.

## Step 1

Specify the measurement model according to `lavaan` syntax.

```{r}
model = "
PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
PA2 =~ P10 + P11 + P12 + P13 + P14
PA3 =~ P15 + P18 + P19 + P20 + P21 + P22
"
```

PA1 ( Teaching Practices ) : P1, P2, P3, P4, P5, P6, P7, P8, P9, P16, P17 (11 items)

PA2 ( Monitoring and Responses) : P10, P11, P12, P13, P14 (5 items)

PA3 ( Involvement ): P15, P18, P19, P20, P21, P22 (6 items)

## Step 2

### Fit the model

```{r}
cfa.model = cfa(model, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model, fit.measures = T, standardized = T)
```

```{r}
standardizedSolution(cfa.model)  # standardized, to view the SE of FL
```

```{r}
parameterEstimates(cfa.model)  # unstandardized, to view the 95% CI
```

Localized areas of misfit,

```{r}
modificationIndices(cfa.model, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model, type="standardized") # find sr > |2.58|
```

```{r}
model2 <- '
  # latent factors
  PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
  PA2 =~ P10 + P11 + P12 + P13 + P14
  PA3 =~ P15 + P18 + P19 + P20 + P21 + P22

  # correlated residuals (based on MI & SR)
  P2 ~~ P3
  P9 ~~ P10
  P16 ~~ P17
  P15 ~~ P19
  P20 ~~ P21
'

fit2 <- cfa(model2, data = data2)
summary(fit2, fit.measures = TRUE, standardized = TRUE)

```

```{r}
model3_syntax <- '
  # Factors (same as your Model 2)
  PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
  PA2 =~ P10 + P11 + P12 + P13 + P14
  PA3 =~ P15 + P18 + P19 + P20 + P21 + P22

  # Keep only theoretically supported & significant residuals
  P2  ~~ P3
  P16 ~~ P17
  P15 ~~ P19

  # NOTE: dropped P9 ~~ P10 and P20 ~~ P21
'

fit3 <- cfa(model3_syntax, data = data2)
summary(fit3, fit.measures = TRUE, standardized = TRUE)
```
