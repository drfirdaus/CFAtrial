---
title: "CFA Attitude V1"
author: "firdaus"
format: 
  html:
    theme: cosmo
    toc: true
    toc-location: left
    toc-depth: 6
    number-sections: true
    self-contained: true
editor: visual
---

# Preliminaries

## Load Library

```{r}
library(readxl)
library(foreign)
library(psych)
library(lavaan)  # for CFA
library(semTools)  # for additional functions in SEM
library(semPlot)  # for path diagram
```

## Load Data

```{r}
data1 = read_excel("CFA_Attitude_V1.xlsx")
names(data1)
head(data1)
dim(data1)

```

Coding the answers

```{r}
# Define mapping functions
likert_map <- function(x) {
  recode <- c(
    "Sangat tidak setuju" = 1,
    "Tidak setuju"        = 2,
    "Tidak pasti"         = 3,
    "Setuju"              = 4,
    "Sangat setuju"       = 5
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

likert_reverse <- function(x) {
  recode <- c(
    "Sangat tidak setuju" = 5,
    "Tidak setuju"        = 4,
    "Tidak pasti"         = 3,
    "Setuju"              = 2,
    "Sangat setuju"       = 1
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

# List of reverse-coded items
reverse_items <- c("A7","A8","A9","A10","A11","A12","A13")

# Apply transformation from data1 -> data2
data2 <- data1

for (col in names(data2)) {
  if (col %in% reverse_items) {
    data2[[col]] <- likert_reverse(data2[[col]])
  } else {
    data2[[col]] <- likert_map(data2[[col]])
  }
}

# Convert all to numeric
data2 <- as.data.frame(lapply(data2, as.numeric))
```

From EFA, we include only good items across PA1 till PA4.

PA3 (Sex Ed Importance ) : A1, A2, A3, A4, A5, A6 (6 item)

PA2 (Sex Ed Concerns) : A7, A8, A9 (3 item)

PA4 (Soc Sensitivity): A10, A11, A12, A13 (4 item)

PA1 (Parent Role): A14, A15, A16, A17, A18, A19, A20, A21, A22 (9 item)

```{r}
data.cfa = data2[c("A1", "A2","A3", "A4", "A5", "A6", "A7", "A8", "A9", "A10", "A11", "A12", "A13", "A14", "A15", "A16", "A17", "A18", "A19", "A20", "A21", "A22")]
```

```{r}
str(data.cfa)
```

```{r}
dim(data.cfa)
```

```{r}
names(data.cfa)
```

```{r}
head(data.cfa)
```

# Confirmatory factor analysis

## Preliminary steps

### **Descriptive statistics**

Check minimum/maximum values per item, and screen for any missing values,

```{r}
describe(data.cfa)
```

Note that all *n* = 201, no missing values. `min`–`max` cover the whole range of response options.

\% of response to options per item,

```{r}
response.frequencies(data.cfa)
```

### **Multivariate normality**

This is done to check the multivariate normality of the data. If the data are normally distributed, we may use maximum likelihood (ML) estimation method for the CFA.

```{r}
mardia(data.cfa)
```

the data are not multivariate normal (`kurtosis` \> 5, *P* \< 0.05). We will use **MLR** in our analysis.

## Step 1

Specify the measurement model according to `lavaan` syntax.

```{r}
model1 = "
PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
PA2 =~ A7 + A8 + A9
PA3 =~ A1 + A2 + A3 + A4 + A5 + A6
PA4 =~ A10 + A11 + A12 + A13
"
```

PA3 (Sex Ed Importance ) : A1, A2, A3, A4, A5, A6 (6 item)

PA2 (Sex Ed Concerns) : A7, A8, A9 (3 item)

PA4 (Soc Sensitivity): A10, A11, A12, A13 (4 item)

PA1 (Parent Role): A14, A15, A16, A17, A18, A19, A20, A21, A22 (9 item)

## Step 2

### Fit the model 1

```{r}
cfa.model1 = cfa(model1, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model1, fit.measures = T, standardized = T)
```

The four-factor CFA model demonstrated marginal fit to the data, χ²(203) = 756.878, p \< .001, CFI = 0.857, TLI = 0.838, RMSEA = 0.136 \[90% CI: 0.125–0.146\], SRMR = 0.064. All standardized loadings were significant (0.535–0.988), supporting convergent validity. Factor correlations ranged from 0.044 to 0.448, indicating adequate discriminant validity. Although the overall model fit did not reach ideal thresholds (CFI ≥ 0.90, RMSEA ≤ 0.08), the pattern of loadings suggests that the hypothesized structure is conceptually sound and may benefit from minor re-specifications or correlated residuals.

```{r}
standardizedSolution(cfa.model1)  # standardized, to view the SE of FL
```

```{r}
parameterEstimates(cfa.model1)  # unstandardized, to view the 95% CI
```

Localized areas of misfit,

```{r}
modificationIndices(cfa.model1, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model1, type="standardized") # find sr > |2.58|
```

## Step 3

### Refine Model 2

```{r}
# Step 1: Add strongest correlated residuals
model2 <- '
  PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
  PA2 =~ A7 + A8 + A9
  PA3 =~ A1 + A2 + A3 + A4 + A5 + A6
  PA4 =~ A10 + A11 + A12 + A13
  
  # Correlated residuals (theoretically justified)
  A12 ~~ A13
'


cfa.model2 = cfa(model2, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model2, fit.measures = T, standardized = T)

```

```{r}
modificationIndices(cfa.model2, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model2, type="standardized") # find sr > |2.58|
```

### Refine Model 3 (Remove A11)

```{r}
model3 <- '
  # Factors
  PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
  PA2 =~ A7  + A8  + A9
  PA3 =~ A1  + A2  + A3  + A4  + A5  + A6
  #remove A11
  PA4 =~ A10 + A12 + A13 
  '

cfa.model3 = cfa(model3, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model3, fit.measures = T, standardized = T)

```

```{r}
modificationIndices(cfa.model3, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model3, type="standardized") # find sr > |2.58|
```

### Refine Model 4

```{r}
model4 <- '
  # Factors
  PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
  PA2 =~ A7  + A8  + A9
  PA3 =~ A1  + A2  + A3  + A4  + A5  + A6
  #remove A11
  PA4 =~ A10 + A12 + A13
  
  A1 ~~ A2
'

cfa.model4 = cfa(model4, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model4, fit.measures = T, standardized = T)
```

```{r}
modificationIndices(cfa.model4, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model4, type="standardized") # find sr > |2.58|
```

### Refine Model 5

```{r}
model5 <- '
  # Factors
  PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
  PA2 =~ A7  + A8  + A9
  PA3 =~ A1  + A2  + A3  + A4  + A5  + A6
  #remove A11
  PA4 =~ A10 + A12 + A13
 
  A1 ~~ A2
  A19 ~~ A20
'

cfa.model5 = cfa(model5, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model5, fit.measures = T, standardized = T)
```

```{r}
modificationIndices(cfa.model5, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model5, type="standardized") # find sr > |2.58|
```

### Model Refine 6

```{r}
model6 <- '
  # Factors
  PA1 =~ A14 + A15 + A16 + A17 + A18 + A19 + A20 + A21 + A22
  PA2 =~ A7  + A8  + A9
  PA3 =~ A1  + A2  + A3  + A4  + A5  + A6
  #remove A11
  PA4 =~ A10 + A12 + A13
  
  A1 ~~ A2
  A19 ~~ A20
  A21 ~~ A22
'

cfa.model6 = cfa(model6, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model6, fit.measures = T, standardized = T)
```

![](images/clipboard-9133593.png)

```{r}
# Grab key measures
want <- c("chisq","df","cfi","tli","rmsea","rmsea.ci.lower","rmsea.ci.upper","srmr")

fm1 <- fitMeasures(cfa.model1, fit.measures = want)
fm3 <- fitMeasures(cfa.model3, fit.measures = want)
fm6 <- fitMeasures(cfa.model6, fit.measures = want)

comp <- rbind(
  Model1 = fm1,
  Model2 = fm3,
  Model3 = fm6,
  Delta  = fm1 - fm6)
round(comp, 3)

```

```{r}
anova(cfa.model1, cfa.model6)   # lavaan will use the Satorra–Bentler scaled test when robust estimators are used

```

# Composite reliability

```{r}
compRelSEM(cfa.model6)
```

# Path diagram

```{r}
semPaths(cfa.model6, 'path', 'std', style = 'lisrel', 
         edge.color = 'black')
```
