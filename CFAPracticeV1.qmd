---
title: "CFA Practice V1"
author: "firdaus"
format: 
  html:
    theme: cosmo
    toc: true
    toc-location: left
    toc-depth: 6
    number-sections: true
    self-contained: true
editor: visual
---

# Preliminaries

## Load Library

```{r}
library(readxl)
library(foreign)
library(psych)
library(lavaan)  # for CFA
library(semTools)  # for additional functions in SEM
library(semPlot)  # for path diagram
```

## Load Data

```{r}
data1 = read_excel("CFA_Practice_V1.xlsx")
names(data1)
head(data1)
dim(data1)

```

Coding the answers

```{r}
# Define mapping function
likert_map <- function(x) {
  recode <- c(
    "Tidak pernah" = 1,
    "Jarang"        = 2,
    "Kadang-kadang"         = 3,
    "Selalu"              = 4,
    "Sentiasa"       = 5
  )
  recode[match(tolower(x), tolower(names(recode)))]
}

# Apply transformation from data1 -> data2
data2 <- data1

for (col in names(data2)) {
  data2[[col]] <- likert_map(data2[[col]])
}

# Convert all to numeric
data2 <- as.data.frame(lapply(data2, as.numeric))
```

From EFA, we include only good items across PA1 till PA3.

PA1 (Teaching Practices) : P1, P2, P3, P4, P5, P6, P7, P8, P9, P16, P17 (11 item)

PA2 (Monitoring) : P10, P11, P12, P13, P14 (5 item)

PA3 (Involvement): P15, P18, P19, P20, P21, P22 (6 item)

```{r}
data.cfa = data2[c("P1", "P2","P3", "P4", "P5", "P6", "P7", "P8", "P9", "P10", "P11", "P12", "P13", "P14", "P15", "P16", "P17", "P18", "P19", "P20", "P21", "P22")]
```

```{r}
str(data.cfa)
```

```{r}
dim(data.cfa)
```

```{r}
names(data.cfa)
```

```{r}
head(data.cfa)
```

# Confirmatory factor analysis

## Preliminary steps

### **Descriptive statistics**

Check minimum/maximum values per item, and screen for any missing values,

```{r}
describe(data.cfa)
```

Note that all *n* = 201, no missing values. `min`–`max` cover the whole range of response options.

\% of response to options per item,

```{r}
response.frequencies(data.cfa)
```

### **Multivariate normality**

This is done to check the multivariate normality of the data. If the data are normally distributed, we may use maximum likelihood (ML) estimation method for the CFA.

```{r}
mardia(data.cfa)
```

the data are not multivariate normal (`kurtosis` \> 5, *P* \< 0.05). We will use **MLR** in our analysis.

## Step 1

Specify the measurement model according to `lavaan` syntax.

```{r}
model1 = "
PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
PA2 =~ P10 + P11 + P12 + P13 + P14 
PA3 =~ P15 + P18 + P19 + P20 + P21 + P22
"
```

PA1 (Teaching Practices) : P1, P2, P3, P4, P5, P6, P7, P8, P9, P16, P17 (11 item)

PA2 (Monitoring) : P10, P11, P12, P13, P14 (5 item)

PA3 (Involvement): P15, P18, P19, P20, P21, P22 (6 item)

## Step 2

### Fit the model 1

```{r}
cfa.model1 = cfa(model1, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model1, fit.measures = T, standardized = T)
```

The four-factor CFA model demonstrated marginal fit to the data, χ²(206) = 568.558, p \< .001, CFI = 0.858, TLI = 0.841, RMSEA = 0.094 \[90% CI: 0.086–0.101\], SRMR = 0.064. All standardized loadings were significant (0.535–0.988), supporting convergent validity. Factor correlations ranged from 0.574 to 0.969, indicating adequate discriminant validity. Although the overall model fit did not reach ideal thresholds (CFI ≥ 0.90, RMSEA ≤ 0.08), the pattern of loadings suggests that the hypothesized structure is conceptually sound and may benefit from minor re-specifications or correlated residuals.

```{r}
standardizedSolution(cfa.model1)  # standardized, to view the SE of FL
```

```{r}
parameterEstimates(cfa.model1)  # unstandardized, to view the 95% CI
```

Localized areas of misfit,

```{r}
modificationIndices(cfa.model1, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model1, type="standardized") # find sr > |2.58|
```

## Step 3

### Refine Model 2

```{r}
# Step 1: Add strongest correlated residuals
model2 <- '
  PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
  PA2 =~ P10 + P11 + P12 + P13 + P14 
  PA3 =~ P15 + P18 + P19 + P20 + P21 + P22
  
  # Correlated residuals (theoretically justified)
  P16 ~~ P17
'


cfa.model2 = cfa(model2, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model2, fit.measures = T, standardized = T)

```

```{r}
modificationIndices(cfa.model2, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model2, type="standardized") # find sr > |2.58|
```

### Refine Model 3

```{r}
model3 <- '
  # Factors
  PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
  PA2 =~ P10 + P11 + P12 + P13 + P14 
  PA3 =~ P15 + P18 + P19 + P20 + P21 + P22
  
  # Correlated residuals (theoretically justified)
  P16 ~~ P17
  P8 ~~ P9
  '

cfa.model3 = cfa(model3, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model3, fit.measures = T, standardized = T)

```

```{r}
modificationIndices(cfa.model3, sort = TRUE, minimum.value = 3.84) # find mi > |3.84|
```

```{r}
residuals(cfa.model3, type="standardized") # find sr > |2.58|
```

### Refine Model 4

```{r}
model4 <- '
  # Factors
  PA1 =~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P16 + P17
  PA2 =~ P10 + P11 + P12 + P13 + P14 
  PA3 =~ P18 + P19 + P20 + P21 + P22
  
  # Correlated residuals (theoretically justified)
  P16 ~~ P17
  P8 ~~ P9
  '

cfa.model4 = cfa(model4, data = data.cfa, estimator = "MLR")
# cfa.model = cfa(model, data = data.cfa, std.lv = 1)  # factor variance = 1
summary(cfa.model4, fit.measures = T, standardized = T)
```

# Comparing the Models

```{r}
# Grab key measures
want <- c(  "chisq.scaled", "df", "cfi.scaled", "tli.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled",  "srmr")

fm1 <- fitMeasures(cfa.model1, fit.measures = want)
fm2 <- fitMeasures(cfa.model2, fit.measures = want)
fm3 <- fitMeasures(cfa.model3, fit.measures = want)
fm4 <- fitMeasures(cfa.model4, fit.measures = want)

comp <- rbind(
  Model1 = fm1,
  Model2 = fm2,
  Model3 = fm3,
  Model4 = fm4,
  Delta  = fm1 - fm4)
round(comp, 3)

```

```{r}
anova(cfa.model1, cfa.model4)   # lavaan will use the Satorra–Bentler scaled test when robust estimators are used

```

# Composite reliability

```{r}
compRelSEM(cfa.model4)
```

# Path diagram

```{r}
semPaths(cfa.model4, 'path', 'std', style = 'lisrel', 
         edge.color = 'black')
```
